{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ID3_tree.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Ipynb_importer\n",
    "import ID3_tree as ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART(Classfication and Regression Tree)是一种著名的决策树算法，分类和回归任务都可以使用。这里仅讨论分类任务。  \n",
    "CART决策树采用“基尼指数”来选择划分属性\n",
    "$$Gini\\left(D\\right)=\\sum_{k=1}^{|y|}\\sum_{j \\neq k}p_kp_j=1-\\sum_{k=1}^{|y|}p_k^2$$\n",
    "直观来说，上式反映了从数据集$D$中随机抽取两个样本，其类别标记不一致的概率，所以该值越小，数据集$D$的纯度越高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(data):\n",
    "    '''\n",
    "    计算基尼值\n",
    "    @param data: 训练数据集\n",
    "    @return gini: 训练数据集的基尼值\n",
    "    '''\n",
    "    classDict = ID3.countLabel(data[:, data.shape[1]-1])\n",
    "    dict2list = np.array(list(classDict.values()))\n",
    "    p_k = dict2list/dict2list.sum()\n",
    "    gini = 1-(p_k**2).sum()\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集$D$的离散属性$a$的基尼指数定义为\n",
    "$$Gini\\_index\\left(D, a\\right)=\\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Gini(D^v)$$\n",
    "我们在侯选属性集合$A$中，选择那个使得划分后基尼指数最小的属性作为最优化分属性，即\n",
    "$$a_*=\\arg \\min_{a \\in A}Gini\\_index\\left(D, a\\right)$$\n",
    "和信息增益相同，对于连续属性$a$的基尼指数\n",
    "$$Gini\\_index\\left(D, a\\right)=\\min_{t\\in T_a}Gain\\_index\\left(D, a, t\\right)=\\min_{t\\in T_a}\\sum\\limits_{\\lambda \\in \\{-, +\\}}\\frac{|D_t^{\\lambda}|}{|D|}Gini\\left(D_t^{\\lambda}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini_index(data, a):\n",
    "    '''\n",
    "    计算基尼指数\n",
    "    @param data: 训练数据集\n",
    "    @param a: 训练数据集属性\n",
    "    @return gini_index: 基尼指数\n",
    "    @return divide: 属性a的划分点\n",
    "    '''\n",
    "    data_a = data[:, a]\n",
    "    data_a_sort = np.unique(data_a) #属性a删除重复值并排序\n",
    "    data_a_sort.sort()\n",
    "    first = np.delete(data_a_sort, len(data_a_sort)-1) #删除最后一个取值\n",
    "    second = np.delete(data_a_sort, 0) #删除第一个取值\n",
    "    T = (first + second)/2 #求得划分点t的集合\n",
    "    \n",
    "    gini_index = 100 #记录属性a的最小基尼指数\n",
    "    divide = 0 #记录划分点t\n",
    "    for t in T:\n",
    "        index_negative = data[:, a]<t #子集Dt-的索引\n",
    "        index_positive = ~index_negative #子集Dt+的索引\n",
    "        negative = data[index_negative]\n",
    "        positive = data[index_positive]\n",
    "        \n",
    "        sum = negative.shape[0]/data.shape[0] * Gini(negative) + positive.shape[0]/data.shape[0] * Gini(positive)\n",
    "        if gini_index > sum:\n",
    "            gini_index = sum\n",
    "            divide = t\n",
    "    \n",
    "    return gini_index, divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(data):\n",
    "    '''\n",
    "    依据基尼指数递归创建CART决策树\n",
    "    @param data: 训练数据集\n",
    "    @return node: 决策树\n",
    "    '''\n",
    "    classDict = ID3.countLabel(data[:, data.shape[1]-1])\n",
    "    #当前集合的类别相同，则返回该类叶节点\n",
    "    if len(classDict) == 1:\n",
    "        return ID3.BTree(list(classDict)[0])\n",
    "    \n",
    "    #当前集合在所有属性上取值相同，则返回样本数最多的类别叶节点\n",
    "    data_feature = data[:, 0:data.shape[1]-1]\n",
    "    if (data_feature[0]==data_feature).astype(int).sum() == data_feature.shape[0]*data_feature.shape[1]:\n",
    "        c = ID3.majorClass(data[:, data.shape[1]-1])\n",
    "        return ID3.BTree(c)\n",
    "    \n",
    "    #求得每个属性的基尼指数和对应划分点\n",
    "    gini_index_list = np.array([])\n",
    "    divide_list = np.array([])\n",
    "    for a in range(data.shape[1]-1):\n",
    "        g, d = Gini_index(data, a)\n",
    "        gini_index_list = np.append(gini_index_list, g)\n",
    "        divide_list = np.append(divide_list, d)\n",
    "        \n",
    "    #选择最小基尼指数索引\n",
    "    index = np.where(gini_index_list == gini_index_list.min())\n",
    "    index = index[0][0]\n",
    "    \n",
    "    node = ID3.BTree(index, divide_list[index])\n",
    "    \n",
    "    #当前集合划分为子集Dt-和Dt+\n",
    "    i = data[:, index] <= divide_list[index]\n",
    "    data_negative = data[i]\n",
    "    data_positive = data[~i]\n",
    "    \n",
    "    node.left = createTree(data_negative)\n",
    "    node.right = createTree(data_positive)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 100.0%\n",
      "test accuracy = 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    path = 'IRIS.csv'\n",
    "    #path = '..\\ex2-logistic_regression\\ex2data3.txt'\n",
    "    data = pd.read_csv(path)\n",
    "    data_train, data_test = ID3.split_data(data.values, 0.2) #数据划分\n",
    "    tree = createTree(data_train) #构造决策树\n",
    "    \n",
    "    #计算预测准确度\n",
    "    mtrain, ntrain = ID3.predict(data_train, tree)\n",
    "    accuracy_train = mtrain/(mtrain + ntrain)\n",
    "\n",
    "    mtest, ntest = ID3.predict(data_test, tree)\n",
    "    accuracy_test = mtest/(mtest + ntest)\n",
    "\n",
    "    print ('train accuracy = {0}%'.format(accuracy_train*100))\n",
    "    print ('test accuracy = {0}%'.format(accuracy_test*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
