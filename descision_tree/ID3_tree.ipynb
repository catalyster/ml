{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'IRIS.csv'\n",
    "#path = '..\\ex2-logistic_regression\\ex2data3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据有几种类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, data.shape[1]-1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,test_ratio):\n",
    "    '''\n",
    "    留出法划分数据集\n",
    "    @param data: 数据集\n",
    "    @param test_ratio: 测试数据集占比\n",
    "    @return data[train_indices]: 训练数据集\n",
    "    @return data[test_indices]: 测试数据集\n",
    "    '''\n",
    "    #np.random.seed(0) #调用此函数会使每次切分来的结果相同\n",
    "    shuffled_indices=np.random.permutation(len(data)) #随机排列序列\n",
    "    test_set_size=int(len(data)*test_ratio)\n",
    "    test_indices =shuffled_indices[:test_set_size]\n",
    "    train_indices=shuffled_indices[test_set_size:]\n",
    "    \n",
    "    return data[train_indices], data[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集切分，训练集：测试集=4：1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 5), (30, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = split_data(data.values, 0.2)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countLabel(y_train):\n",
    "    '''\n",
    "    字典统计不同类型标签的出现次数\n",
    "    @param y_train: 训练数据集标签\n",
    "    @return classDict: 标签统计次数\n",
    "    '''\n",
    "    classDict = {}\n",
    "    for label in y_train:\n",
    "        if label in classDict.keys():\n",
    "            classDict[label] += 1\n",
    "        else:\n",
    "            classDict[label] = 1\n",
    "    return classDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorClass(y_train):\n",
    "    '''\n",
    "    找到当前集合中最多的标签\n",
    "    @param y_train: 训练数据集标签\n",
    "    @return 训练数据中最多的标签\n",
    "    '''\n",
    "    classDict = countLabel(y_train)\n",
    "    #对字典进行降序排序,内置sorted(),key参数，用于指定在作比较之前，调用何种函数对列表元素进行处理\n",
    "    classSort = sorted(classDict.items(), key = lambda x:x[1], reverse=True)\n",
    "    return classSort[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算当前集合的信息熵，${P}_{k}$是当前集合样本$D$中第$k$类样本所占比例，${k}=1, 2, ..., {|y|}$。\n",
    "$$ Ent\\left(D\\right)=-\\sum\\limits_{k=1}^{|y|}{P}_{k}{\\log}_{2}{P}_{k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_entropy(y_train):\n",
    "    '''\n",
    "    计算信息熵\n",
    "    @param y_train: 训练数据集标签\n",
    "    @return Ent: 训练数据集的信息熵\n",
    "    '''\n",
    "    classDict = countLabel(y_train)\n",
    "    dict2list = np.array(list(classDict.values()))\n",
    "    p_k = dict2list/dict2list.sum()\n",
    "    Ent = -(p_k*np.log2(p_k)).sum()\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算当前集合$D$某一离散属性$a$的信息增益，$a$有$V$个可能取值$\\{a^1, a^2, ..., a^v\\}$\n",
    "$$Gain\\left(D, a\\right)=Ent\\left(D\\right)-\\sum\\limits_{v=1}^{V}\\frac{|D^v|}{|D|}Ent\\left(D^v\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于连续属性$a$的信息增益，假定$a$在$D$上出现了$n$个不同的取值，将这些值从小到大排列，记为$\\{a^1, a^2, ...,a^n\\}$。基于划分点$t$可将$D$分为子集$D_t^-$和$D_t^+$。\n",
    "$$T_a=\\left\\{\\frac{a^i+a^{i+1}}{2}|{1\\leq i\\leq n-1}\\right\\}$$\n",
    "$$Gain\\left(D, a\\right)=\\max_{t\\in T_a}Gain\\left(D, a, t\\right)=\\max_{t\\in T_a}\\left\\{Ent\\left(D\\right)-\\sum\\limits_{\\lambda \\in \\{-, +\\}}\\frac{|D_t^{\\lambda}|}{|D|}Ent\\left(D_t^{\\lambda}\\right)\\right\\}$$\n",
    "需要注意的是，与离散属性不同，若当前结点的划分属性是连续属性，该属性还可作为其后代结点的划分属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data, a):\n",
    "    '''\n",
    "    计算关于属性a的信息增益\n",
    "    @param data: 训练数据集\n",
    "    @param a: 训练数据集属性\n",
    "    @return Gain: 训练数据集的信息增益\n",
    "    @return divide: 属性a的划分点\n",
    "    '''\n",
    "    data_a = data[:, a]\n",
    "    data_a_sort = np.unique(data_a) #属性a删除重复值并排序\n",
    "    data_a_sort.sort()\n",
    "    first = np.delete(data_a_sort, len(data_a_sort)-1) #删除最后一个取值\n",
    "    second = np.delete(data_a_sort, 0) #删除第一个取值\n",
    "    T = (first + second)/2 #求得划分点t\n",
    "    data_section = np.take(data, [a, data.shape[1]-1], axis=1) #获取数据a属性列和标签列\n",
    "    \n",
    "    #集合data的信息熵\n",
    "    Ent = information_entropy(data[:, data.shape[1]-1])\n",
    "    \n",
    "    #记录属性a的最小条件熵，初始值为该集合信息熵最大值log2(|D|)\n",
    "    classDict = countLabel(data[:, data.shape[1]-1])\n",
    "    min = np.log2(len(classDict))\n",
    "    divide=0\n",
    "    for t in T:\n",
    "        index_negative = data_section[:, 0]<t #子集Dt-的索引\n",
    "        index_positive = ~index_negative #子集Dt+的索引\n",
    "        negative = data_section[index_negative]\n",
    "        positive = data_section[index_positive]\n",
    "        \n",
    "        sum = (negative.shape[0]/data_section.shape[0])*information_entropy(negative[:, 1])\\\n",
    "                +(positive.shape[0]/data_section.shape[0])*information_entropy(positive[:, 1])\n",
    "        if min > sum:\n",
    "            min = sum\n",
    "            divide = t\n",
    "            \n",
    "    Gain = Ent-min\n",
    "    return Gain, divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义二叉树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTree(object):\n",
    "    #初始化\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None):\n",
    "        self.feature = feature #划分属性\n",
    "        self.value = value    # 划分值\n",
    "        self.left = left    # 左子树\n",
    "        self.right = right  # 右子树\n",
    "        \n",
    "    #前序遍历\n",
    "    def preorder(self):\n",
    "        if self.feature is not None:\n",
    "            print(self.feature, self.value, end=' ')\n",
    "        if self.left is not None:\n",
    "            self.left.preorder()\n",
    "        if self.right is not None:\n",
    "            self.right.preorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(data):\n",
    "    '''\n",
    "    依据信息增益递归创建ID3决策树\n",
    "    @param data: 训练数据集\n",
    "    @return node: 决策树\n",
    "    '''\n",
    "    classDict = countLabel(data[:, data.shape[1]-1])\n",
    "    #当前集合的类别相同，则返回该类叶节点\n",
    "    if len(classDict) == 1:\n",
    "        return BTree(list(classDict)[0])\n",
    "    \n",
    "    #当前集合在所有属性上取值相同，则返回样本数最多的类别叶节点\n",
    "    data_feature = data[:, 0:data.shape[1]-1]\n",
    "    if (data_feature[0]==data_feature).astype(int).sum() == data_feature.shape[0]*data_feature.shape[1]:\n",
    "        c = majorClass(data[:, data.shape[1]-1])\n",
    "        return BTree(c)\n",
    "    \n",
    "    #求得每个属性的信息增益和对应划分点\n",
    "    gain_list = np.array([])\n",
    "    divide_list = np.array([])\n",
    "    #求得每个属性的信息增益和对应划分点\n",
    "    for a in range(data.shape[1]-1):\n",
    "        g, d = information_gain(data, a)\n",
    "        gain_list = np.append(gain_list, g)\n",
    "        divide_list = np.append(divide_list, d)\n",
    "        \n",
    "    #求得最大信息增益索引\n",
    "    index = np.where(gain_list == gain_list.max())\n",
    "    index = index[0][0]\n",
    "    \n",
    "    node = BTree(index, divide_list[index])\n",
    "    \n",
    "    #当前集合划分为子集Dt-和Dt+\n",
    "    i = data[:, index] <= divide_list[index]\n",
    "    data_negative = data[i]\n",
    "    data_positive = data[~i]\n",
    "    \n",
    "    node.left = createTree(data_negative)\n",
    "    node.right = createTree(data_positive)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, tree):\n",
    "    '''\n",
    "    类别预测准确度\n",
    "    @param data: 训练数据集\n",
    "    @param tree: 决策树\n",
    "    @return m: 正确分类个数\n",
    "    @return n: 错误分类个数\n",
    "    '''\n",
    "    index = tree.feature\n",
    "    if tree.value is not None: #非叶结点，即有左右子树\n",
    "        value = tree.value\n",
    "        i = data[:, index] <= value\n",
    "        data_negative = data[i]\n",
    "        data_positive = data[~i]\n",
    "        mleft, nleft = predict(data_negative, tree.left)\n",
    "        mright, nright = predict(data_positive, tree.right)\n",
    "        m = mleft + mright\n",
    "        n = nleft + nright\n",
    "        return m, n\n",
    "    else: #叶结点\n",
    "        m = (data[:, data.shape[1]-1] == tree.feature).astype(int).sum() #预测正确个数\n",
    "        n = data.shape[0]-m #预测错误个数\n",
    "        return m, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算训练集和测试集的预测准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 100.0%\n",
      "test accuracy = 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    tree = createTree(data_train) #训练决策树\n",
    "    \n",
    "    #计算预测准确度\n",
    "    mtrain, ntrain = predict(data_train, tree)\n",
    "    accuracy_train = mtrain/(mtrain + ntrain)\n",
    "\n",
    "    mtest, ntest = predict(data_test, tree)\n",
    "    accuracy_test = mtest/(mtest + ntest)\n",
    "\n",
    "    print ('train accuracy = {0}%'.format(accuracy_train*100))\n",
    "    print ('test accuracy = {0}%'.format(accuracy_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
