{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4.5 tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'IRIS.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集合$D$的信息熵，${P}_{k}$是当前集合样本$D$中第$k$类样本所占比例，${k}=1, 2, ..., {|y|}$。\n",
    "$$ Ent\\left(D\\right)=-\\sum\\limits_{k=1}^{|y|}{P}_{k}{\\log}_{2}{P}_{k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前集合$D$某一离散属性$a$的信息增益，$a$有$V$个可能取值$\\{a^1, a^2, ..., a^v\\}$\n",
    "$$Gain\\left(D, a\\right)=Ent\\left(D\\right)-\\sum\\limits_{v=1}^{V}\\frac{|D^v|}{|D|}Ent\\left(D^v\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于连续属性$a$的信息增益，假定$a$在$D$上出现了$n$个不同的取值，将这些值从小到大排列，记为$\\{a^1, a^2, ...,a^n\\}$。基于划分点$t$可将$D$分为子集$D_t^-$和$D_t^+$。\n",
    "$$T_a=\\left\\{\\frac{a^i+a^{i+1}}{2}|{1\\leq i\\leq n-1}\\right\\}$$\n",
    "$$Gain\\left(D, a\\right)=\\max_{t\\in T_a}Gain\\left(D, a, t\\right)=\\max_{t\\in T_a}\\left\\{Ent\\left(D\\right)-\\sum\\limits_{\\lambda \\in \\{-, +\\}}\\frac{|D_t^{\\lambda}|}{|D|}Ent\\left(D_t^{\\lambda}\\right)\\right\\}$$\n",
    "需要注意的是，与离散属性不同，若当前结点的划分属性是连续属性，该属性还可作为其后代结点的划分属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3决策树使用信息增益来选择最优化分属性，但是信息增益准则对可取值数目较多的属性有所偏好。为了减少这种偏好带来的不利影响，C4.5决策树采用增益率来选择最优划分属性。\n",
    "$$Gain\\_ratio\\left(D, a\\right)=\\frac{Gain\\left(D, a\\right)}{IV\\left(a\\right)}$$\n",
    "其中$IV\\left(a\\right)$称为属性$a$的固有值（intrisic value），对于离散属性$a$\n",
    "$$IV\\left(a\\right)=-\\sum\\limits_{v=1}^{V}\\frac{|D^{v}|}{|D|}{\\log}_{2}\\frac{|D^{v}|}{|D|}$$\n",
    "对于连续属性$a$\n",
    "$$IV\\left(a\\right)=-\\sum\\limits_{\\lambda \\in \\{-, +\\}}\\frac{|D^{\\lambda}|}{|D|}{\\log}_{2}\\frac{|D^{\\lambda}|}{|D|}$$\n",
    "需要注意的是，增益率准则对可取值数目较少的属性有所偏好，所以C4.5决策树使用了一个启发式方法：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ID3_tree.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer #jupyter notebook解析文件,方便调用其他upyter notebook文件\n",
    "import ID3_tree as ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrisic_value(data, divide):\n",
    "    '''\n",
    "    计算属性a的固有值\n",
    "    @param data:训练数据集\n",
    "    @param divide:属性a的最优化分点\n",
    "    @return IV:属性a的固有值\n",
    "    '''\n",
    "    index_negative = data[:, 0]<divide #子集Dt-的索引\n",
    "    index_positive = ~index_negative #子集Dt+的索引\n",
    "    negative = data[index_negative]\n",
    "    positive = data[index_positive]\n",
    "    sumD = negative.shape[0] + positive.shape[0]\n",
    "    #log()加上1e-6,防止溢出\n",
    "    IV = -negative.shape[0]/sumD * np.log2(negative.shape[0]/sumD + 1e-6) \\\n",
    "        - positive.shape[0]/sumD * np.log2(positive.shape[0]/sumD + 1e-6)\n",
    "    \n",
    "    return IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_and_ratio(data, a):\n",
    "    '''\n",
    "    计算关于属性a的信息增益和增益率\n",
    "    @param data: 训练数据集\n",
    "    @param a: 训练数据集属性\n",
    "    @return Gain: 训练数据集的信息增益\n",
    "    @return divide: 属性a的划分点\n",
    "    @return ratio: 属性a的增益率\n",
    "    '''\n",
    "    cols = data.shape[1]\n",
    "    data_a = data[:, a]\n",
    "    data_a_sort = np.unique(data_a) #属性a删除重复值并排序\n",
    "    data_a_sort.sort()\n",
    "    first = np.delete(data_a_sort, len(data_a_sort)-1) #删除最后一个取值\n",
    "    second = np.delete(data_a_sort, 0) #删除第一个取值\n",
    "    T = (first + second)/2 #求得划分点t\n",
    "    data_section = np.take(data, [a, cols-1], axis=1) #获取数据a属性列和标签列\n",
    "    \n",
    "    #集合data的信息熵\n",
    "    Ent = ID3.information_entropy(data[:, cols-1])\n",
    "    \n",
    "    #记录属性a的最小条件熵，初始值为该集合信息熵最大值log2(|D|)\n",
    "    classDict = ID3.countLabel(data[:, cols-1])\n",
    "    min = np.log2(len(classDict))\n",
    "    divide=0 #记录划分点\n",
    "    for t in T:\n",
    "        index_negative = data_section[:, 0]<t #子集Dt-的索引\n",
    "        index_positive = ~index_negative #子集Dt+的索引\n",
    "        negative = data_section[index_negative]\n",
    "        positive = data_section[index_positive]\n",
    "        \n",
    "        sum = (negative.shape[0]/data_section.shape[0])*ID3.information_entropy(negative[:, 1])\\\n",
    "                +(positive.shape[0]/data_section.shape[0])*ID3.information_entropy(positive[:, 1])\n",
    "        if min > sum:\n",
    "            min = sum\n",
    "            divide = t\n",
    "    \n",
    "    IV = intrisic_value(data_section, divide) #属性a的固有值\n",
    "    Gain = Ent-min #属性a的信息增益\n",
    "    ratio = Gain/IV #属性a的增益率\n",
    "    \n",
    "    return Gain, divide, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 5), (30, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = ID3.split_data(data.values, 0.2)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6063301504633138, 5.55, 0.6214856084998776)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_and_ratio(data_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(data):\n",
    "    '''\n",
    "    依据信息增益和增益率递归创建C4.5决策树\n",
    "    @param data: 训练数据集\n",
    "    @return node: 决策树\n",
    "    '''\n",
    "    classDict = ID3.countLabel(data[:, data.shape[1]-1])\n",
    "    #当前集合的类别相同，则返回该类叶节点\n",
    "    if len(classDict) == 1:\n",
    "        return ID3.BTree(list(classDict)[0])\n",
    "    \n",
    "    #当前集合在所有属性上取值相同，则返回样本数最多的类别叶节点\n",
    "    data_feature = data[:, 0:data.shape[1]-1]\n",
    "    if (data_feature[0]==data_feature).astype(int).sum() == data_feature.shape[0]*data_feature.shape[1]:\n",
    "        c = ID3.majorClass(data[:, data.shape[1]-1])\n",
    "        return ID3.BTree(c)\n",
    "    \n",
    "    #求得每个属性的信息增益、对应划分点和增益率\n",
    "    gain_list = np.array([])\n",
    "    divide_list = np.array([])\n",
    "    ratio_list = np.array([])\n",
    "    #求得每个属性的信息增益和对应划分点\n",
    "    for a in range(data.shape[1]-1):\n",
    "        g, d, r = information_gain_and_ratio(data, a)\n",
    "        gain_list = np.append(gain_list, g)\n",
    "        divide_list = np.append(divide_list, d)\n",
    "        ratio_list = np.append(ratio_list, r)\n",
    "        \n",
    "    #求得大于信息增益均值的索引\n",
    "    index = np.where(gain_list > gain_list.mean())\n",
    "    index = index[0]\n",
    "    #信息增益高于平均水平的属性，再从中选择增益率最高的\n",
    "    index = np.where(ratio_list == ratio_list[index].max())\n",
    "    index = index[0][0]\n",
    "    \n",
    "    node = ID3.BTree(index, divide_list[index])\n",
    "    \n",
    "    #当前集合划分为子集Dt-和Dt+\n",
    "    i = data[:, index] <= divide_list[index]\n",
    "    data_negative = data[i]\n",
    "    data_positive = data[~i]\n",
    "    \n",
    "    node.left = createTree(data_negative)\n",
    "    node.right = createTree(data_positive)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 100.0%\n",
      "test accuracy = 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #数据集划分\n",
    "    data_train, data_test = ID3.split_data(data.values, 0.2)\n",
    "    tree = createTree(data_train) #训练决策树\n",
    "    \n",
    "    #计算预测准确度\n",
    "    mtrain, ntrain = ID3.predict(data_train, tree)\n",
    "    accuracy_train = mtrain/(mtrain + ntrain)\n",
    "\n",
    "    mtest, ntest = ID3.predict(data_test, tree)\n",
    "    accuracy_test = mtest/(mtest + ntest)\n",
    "\n",
    "    print ('train accuracy = {0}%'.format(accuracy_train*100))\n",
    "    print ('test accuracy = {0}%'.format(accuracy_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
